{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hoa92ng/Homework/blob/main/Welcome_To_Colaboratory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test"
      ],
      "metadata": {
        "id": "2FjSTqsjWtvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchaudio\n",
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the dataset\n",
        "# train_dataset = load_dataset(\"google/speech_commands\", 'v0.01', split='train', trust_remote_code=True)\n",
        "valid_dataset = load_dataset(\"google/speech_commands\", 'v0.01', split='validation', trust_remote_code=True)\n",
        "\n",
        "print(valid_dataset)\n",
        "\n",
        "# # Example: Load the first audio file in the dataset\n",
        "first_sample = valid_dataset[0]\n",
        "dict_label = {'yes':0,\n",
        "              'no':1,\n",
        "              'up':2,\n",
        "              'down':3,\n",
        "              'left':4,\n",
        "              'right':5,\n",
        "              'on':6,\n",
        "              'off':7,\n",
        "              'stop':8,\n",
        "              'go':9,\n",
        "              'unknown':10,\n",
        "              'silence':11}\n",
        "\n",
        "labels = valid_dataset.features[\"label\"].names\n",
        "label2id, id2label = dict(), dict()\n",
        "for i, label in enumerate(labels):\n",
        "    label2id[label] = str(i)\n",
        "    id2label[str(i)] = label\n",
        "\n",
        "def edit_exam(examples):\n",
        "    for i, label in enumerate(examples):\n",
        "        label2id[label] = str(i)\n",
        "        id2label[str(i)] = label\n",
        "        # valid_dataset.features['label'].names = ['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', '_silence_']\n",
        "        for i, x in enumerate(examples['file']):\n",
        "            a = examples['label'][i]\n",
        "            if examples['is_unknown'][i]: examples['label'][i] = dict_label['unknown']\n",
        "            elif id2label[str(examples['label'][i])] == '_silence_':\n",
        "                examples['label'][i] = dict_label['silence']\n",
        "    return examples\n",
        "\n",
        "\n",
        "\n",
        "valid_dataset = valid_dataset.map(edit_exam, batched=True)\n",
        "df = valid_dataset.to_pandas()\n",
        "# Giả sử cột label trong dataset có tên là 'label'\n",
        "label_counts = df['label'].value_counts()\n",
        "\n",
        "# Hiển thị kết quả\n",
        "print(label_counts)\n",
        "\n",
        "# Hiển thị đồ thị\n",
        "label_counts.plot(kind='bar')\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Số lượng')\n",
        "plt.title('Số lượng mỗi class trong cột label')\n",
        "plt.show()\n",
        "# valid_dataset.features['label'].names = ['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence']\n",
        "# first_sample"
      ],
      "metadata": {
        "id": "eNzSSt57cFzE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoFeatureExtractor\n",
        "from datasets import load_dataset, Audio\n",
        "from transformers import AutoModelForAudioClassification, TrainingArguments, Trainer\n",
        "import numpy as np\n",
        "import evaluate\n",
        "accuracy = evaluate.load(\"accuracy\")\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "dict_label = {'yes':0,\n",
        "              'no':1,\n",
        "              'up':2,\n",
        "              'down':3,\n",
        "              'left':4,\n",
        "              'right':5,\n",
        "              'on':6,\n",
        "              'off':7,\n",
        "              'stop':8,\n",
        "              'go':9,\n",
        "              'unknown':10,\n",
        "              'silence':11}\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions = np.argmax(eval_pred.predictions, axis=1)\n",
        "    return accuracy.compute(predictions=predictions, references=eval_pred.label_ids)\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    audio_arrays = [x[\"array\"] for x in examples[\"audio\"]]\n",
        "    inputs = feature_extractor(\n",
        "        audio_arrays, sampling_rate=feature_extractor.sampling_rate, max_length=16_000, truncation=True\n",
        "    )\n",
        "    return inputs\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def edit_label(examples):\n",
        "    # valid_dataset.features['label'].names = ['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', '_silence_']\n",
        "    for i, x in enumerate(examples['file']):\n",
        "        a = examples['label'][i]\n",
        "        if examples['is_unknown'][i]: examples['label'][i] = dict_label['unknown']\n",
        "        elif id2label[str(examples['label'][i])] == '_silence_':\n",
        "            examples['label'][i] = dict_label['silence']\n",
        "    return examples\n",
        "\n",
        "feature_extractor = AutoFeatureExtractor.from_pretrained('./model_1')\n",
        "train_dataset_ = load_dataset(\"google/speech_commands\", 'v0.01', split='train', trust_remote_code=True)\n",
        "valid_dataset_ = load_dataset(\"google/speech_commands\", 'v0.01', split='validation', trust_remote_code=True)\n",
        "\n",
        "\n",
        "labels = valid_dataset_.features[\"label\"].names\n",
        "label2id, id2label = dict(), dict()\n",
        "for i, label in enumerate(labels):\n",
        "    label2id[label] = str(i)\n",
        "    id2label[str(i)] = label\n",
        "\n",
        "\n",
        "train_dataset_ = train_dataset_.map(edit_label, batched=True)\n",
        "valid_dataset_ = valid_dataset_.map(edit_label, batched=True)\n",
        "\n",
        "\n",
        "df = train_dataset_.to_pandas()\n",
        "# Giả sử cột label trong dataset có tên là 'label'\n",
        "label_counts = df['label'].value_counts()\n",
        "\n",
        "# Hiển thị kết quả\n",
        "print(label_counts)\n",
        "\n",
        "# Hiển thị đồ thị\n",
        "label_counts.plot(kind='bar')\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Số lượng')\n",
        "plt.title('Số lượng mỗi class trong cột label')\n",
        "plt.show()\n",
        "\n",
        "train_dataset_ = train_dataset_.remove_columns([\"file\", \"is_unknown\", \"speaker_id\", \"utterance_id\"])\n",
        "valid_dataset_ = valid_dataset_.remove_columns([\"file\", \"is_unknown\", \"speaker_id\", \"utterance_id\"])\n",
        "\n",
        "labels = dict_label.keys()\n",
        "label2id, id2label = dict(), dict()\n",
        "for i, label in enumerate(labels):\n",
        "    label2id[label] = str(i)\n",
        "    id2label[str(i)] = label\n",
        "print(label2id)\n",
        "\n",
        "\n",
        "\n",
        "train_data = train_dataset_.cast_column(\"audio\", Audio(sampling_rate=16_000))\n",
        "valid_data = valid_dataset_.cast_column(\"audio\", Audio(sampling_rate=16_000))\n",
        "\n",
        "encoded_data_train = train_data.map(preprocess_function, remove_columns=\"audio\", batched=True)\n",
        "encoded_data_validation = valid_data.map(preprocess_function, remove_columns=\"audio\", batched=True)\n",
        "print(encoded_data_train)\n",
        "\n",
        "num_labels = len(id2label)\n",
        "model = AutoModelForAudioClassification.from_pretrained(\n",
        "    \"./model_1\", num_labels=num_labels, label2id=label2id, id2label=id2label\n",
        ")\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"my_awesome_mind_model\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=3e-5,\n",
        "    per_device_train_batch_size=32,\n",
        "    gradient_accumulation_steps=4,\n",
        "    per_device_eval_batch_size=32,\n",
        "    num_train_epochs=10,\n",
        "    warmup_ratio=0.1,\n",
        "    logging_steps=10,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    push_to_hub=False,\n",
        "    report_to='none',\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=encoded_data_train.with_format(\"torch\"),\n",
        "    eval_dataset=encoded_data_validation.with_format(\"torch\"),\n",
        "    tokenizer=feature_extractor,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "VVLxrGVw_FdR"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colaboratory",
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}