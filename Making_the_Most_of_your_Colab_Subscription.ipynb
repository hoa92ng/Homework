{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hoa92ng/Homework/blob/main/Making_the_Most_of_your_Colab_Subscription.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKQ4bH7qMGrA"
      },
      "source": [
        "# Making the Most of your Colab Subscription\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMMqmdiYMkvi"
      },
      "source": [
        "## Faster GPUs\n",
        "\n",
        "Users who have purchased one of Colab's paid plans have access to faster GPUs and more memory. You can upgrade your notebook's GPU settings in `Runtime > Change runtime type` in the menu to select from several accelerator options, subject to availability.\n",
        "\n",
        "The free of charge version of Colab grants access to Nvidia's T4 GPUs subject to quota restrictions and availability.\n",
        "\n",
        "You can see what GPU you've been assigned at any time by executing the following cell. If the execution result of running the code cell below is \"Not connected to a GPU\", you can change the runtime by going to `Runtime > Change runtime type` in the menu to enable a GPU accelerator, and then re-execute the code cell.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23TOba33L4qf"
      },
      "outputs": [],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sa-IrJS1aRVJ"
      },
      "source": [
        "In order to use a GPU with your notebook, select the `Runtime > Change runtime type` menu, and then set the hardware accelerator to the desired option."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65MSuHKqNeBZ"
      },
      "source": [
        "## More memory\n",
        "\n",
        "Users who have purchased one of Colab's paid plans have access to high-memory VMs when they are available. More powerful GPUs are always offered with high-memory VMs.\n",
        "\n",
        "\n",
        "\n",
        "You can see how much memory you have available at any time by running the following code cell. If the execution result of running the code cell below is \"Not using a high-RAM runtime\", then you can enable a high-RAM runtime via `Runtime > Change runtime type` in the menu. Then select High-RAM in the Runtime shape toggle button. After, re-execute the code cell.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V1G82GuO-tez"
      },
      "outputs": [],
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJW8Qi-pPpep"
      },
      "source": [
        "## Longer runtimes\n",
        "\n",
        "All Colab runtimes are reset after some period of time (which is faster if the runtime isn't executing code). Colab Pro and Pro+ users have access to longer runtimes than those who use Colab free of charge.\n",
        "\n",
        "## Background execution\n",
        "\n",
        "Colab Pro+ users have access to background execution, where notebooks will continue executing even after you've closed a browser tab. This is always enabled in Pro+ runtimes as long as you have compute units available.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLlTRcMM_h0k"
      },
      "source": [
        "## Relaxing resource limits in Colab Pro\n",
        "\n",
        "Your resources are not unlimited in Colab. To make the most of Colab, avoid using resources when you don't need them. For example, only use a GPU when required and close Colab tabs when finished.\n",
        "\n",
        "\n",
        "\n",
        "If you encounter limitations, you can relax those limitations by purchasing more compute units via Pay As You Go. Anyone can purchase compute units via [Pay As You Go](https://colab.research.google.com/signup); no subscription is required."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mm8FzEidvPs6"
      },
      "source": [
        "## Send us feedback!\n",
        "\n",
        "If you have any feedback for us, please let us know. The best way to send feedback is by using the Help > 'Send feedback...' menu. If you encounter usage limits in Colab Pro consider subscribing to Pro+.\n",
        "\n",
        "If you encounter errors or other issues with billing (payments) for Colab Pro, Pro+, or Pay As You Go, please email [colab-billing@google.com](mailto:colab-billing@google.com)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qB3bdLe8jkAa"
      },
      "source": [
        "## More Resources\n",
        "\n",
        "### Working with Notebooks in Colab\n",
        "- [Overview of Colab](/notebooks/basic_features_overview.ipynb)\n",
        "- [Guide to Markdown](/notebooks/markdown_guide.ipynb)\n",
        "- [Importing libraries and installing dependencies](/notebooks/snippets/importing_libraries.ipynb)\n",
        "- [Saving and loading notebooks in GitHub](https://colab.research.google.com/github/googlecolab/colabtools/blob/main/notebooks/colab-github-demo.ipynb)\n",
        "- [Interactive forms](/notebooks/forms.ipynb)\n",
        "- [Interactive widgets](/notebooks/widgets.ipynb)\n",
        "\n",
        "<a name=\"working-with-data\"></a>\n",
        "### Working with Data\n",
        "- [Loading data: Drive, Sheets, and Google Cloud Storage](/notebooks/io.ipynb)\n",
        "- [Charts: visualizing data](/notebooks/charts.ipynb)\n",
        "- [Getting started with BigQuery](/notebooks/bigquery.ipynb)\n",
        "\n",
        "### Machine Learning Crash Course\n",
        "These are a few of the notebooks from Google's online Machine Learning course. See the [full course website](https://developers.google.com/machine-learning/crash-course/) for more.\n",
        "- [Intro to Pandas DataFrame](https://colab.research.google.com/github/google/eng-edu/blob/main/ml/cc/exercises/pandas_dataframe_ultraquick_tutorial.ipynb)\n",
        "- [Linear regression with tf.keras using synthetic data](https://colab.research.google.com/github/google/eng-edu/blob/main/ml/cc/exercises/linear_regression_with_synthetic_data.ipynb)\n",
        "\n",
        "\n",
        "<a name=\"using-accelerated-hardware\"></a>\n",
        "### Using Accelerated Hardware\n",
        "- [TensorFlow with GPUs](/notebooks/gpu.ipynb)\n",
        "- [TensorFlow with TPUs](/notebooks/tpu.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFm2S0Gijqo8"
      },
      "source": [
        "<a name=\"machine-learning-examples\"></a>\n",
        "\n",
        "## Machine Learning Examples\n",
        "\n",
        "To see end-to-end examples of the interactive machine learning analyses that Colab makes possible, check out these tutorials using models from [TensorFlow Hub](https://tfhub.dev).\n",
        "\n",
        "A few featured examples:\n",
        "\n",
        "- [Retraining an Image Classifier](https://tensorflow.org/hub/tutorials/tf2_image_retraining): Build a Keras model on top of a pre-trained image classifier to distinguish flowers.\n",
        "- [Text Classification](https://tensorflow.org/hub/tutorials/tf2_text_classification): Classify IMDB movie reviews as either *positive* or *negative*.\n",
        "- [Style Transfer](https://tensorflow.org/hub/tutorials/tf2_arbitrary_image_stylization): Use deep learning to transfer style between images.\n",
        "- [Multilingual Universal Sentence Encoder Q&A](https://tensorflow.org/hub/tutorials/retrieval_with_tf_hub_universal_encoder_qa): Use a machine learning model to answer questions from the SQuAD dataset.\n",
        "- [Video Interpolation](https://tensorflow.org/hub/tutorials/tweening_conv3d): Predict what happened in a video between the first and the last frame.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "from transformers import Wav2Vec2Model, AutoModelForAudioClassification\n",
        "from transformers import AutoFeatureExtractor\n",
        "from datasets import Dataset, DatasetDict\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "def init_weight(m):\n",
        "    if isinstance(m, torch.nn.Linear):\n",
        "        torch.nn.init.xavier_normal_(m.weight)\n",
        "    if isinstance(m, torch.nn.BatchNorm2d):\n",
        "        m.weight.data.normal_(1.0, 0.02)\n",
        "        m.bias.data.fill_(0)\n",
        "    elif isinstance(m, torch.nn.Conv2d):\n",
        "        m.weight.data.normal_(0.0, 0.02)\n",
        "\n",
        "\n",
        "class Projection(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, in_planes, out_planes=None, n_layers=1, layer_type=0):\n",
        "        super(Projection, self).__init__()\n",
        "        self.out_planes = out_planes\n",
        "        if out_planes is None:\n",
        "            out_planes = in_planes\n",
        "        self.layers = torch.nn.Sequential()\n",
        "        _in = None\n",
        "        _out = None\n",
        "        for i in range(n_layers):\n",
        "            # self.layers.add_module(f\"{i}fc\",\n",
        "            #                        torch.nn.Linear(_in, _out))\n",
        "            self.layers.add_module(f\"{i}cv1d\",\n",
        "                                   torch.nn.Conv1d(in_planes, in_planes, 3, padding='same'))\n",
        "            self.layers.add_module(f\"{i}bn\",\n",
        "                                    torch.nn.BatchNorm1d(in_planes))\n",
        "\n",
        "            if layer_type == n_layers - 1:\n",
        "                self.layers.add_module(f\"{i}relu\",\n",
        "                                            torch.nn.LeakyReLU(.2))\n",
        "            # if i < n_layers - 1:\n",
        "            #     # if layer_type > 0:\n",
        "            #     #     self.layers.add_module(f\"{i}bn\",\n",
        "            #     #                            torch.nn.BatchNorm1d(_out))\n",
        "            #     if layer_type > 1:\n",
        "            #         self.layers.add_module(f\"{i}relu\",\n",
        "            #                                torch.nn.LeakyReLU(.2))\n",
        "        self.apply(init_weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x = .1 * self.layers(x) + x\n",
        "        x = self.layers(x)\n",
        "        # x = x.reshape(x.shape[0],-1)\n",
        "        # x = F.adaptive_avg_pool1d(x, self.out_planes)\n",
        "        x = x.mean(dim=1)\n",
        "        return x\n",
        "\n",
        "class Discriminator(torch.nn.Module):\n",
        "    def __init__(self, in_planes, n_layers=3, hidden=None):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        _hidden = in_planes if hidden is None else hidden\n",
        "        self.body = torch.nn.Sequential()\n",
        "        for i in range(n_layers-1):\n",
        "            _in = in_planes if i == 0 else _hidden\n",
        "            _hidden = int(_hidden // 1.5) if hidden is None else hidden\n",
        "            self.body.add_module('block%d'%(i+1),\n",
        "                                 torch.nn.Sequential(\n",
        "                                    #  nn.Dropout(0.2),\n",
        "                                     torch.nn.Linear(_in, _hidden),\n",
        "                                     torch.nn.BatchNorm1d(_hidden),\n",
        "                                     torch.nn.LeakyReLU(0.2)\n",
        "                                 ))\n",
        "        self.tail = torch.nn.Linear(_hidden, 1)\n",
        "        self.apply(init_weight)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.body(x)\n",
        "        x = self.tail(x)\n",
        "        return x\n",
        "\n",
        "class Discriminator_Conv(torch.nn.Module):\n",
        "    def __init__(self, in_planes, n_layers=3, hidden=None):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        _hidden = in_planes if hidden is None else hidden\n",
        "        self.body = torch.nn.Sequential()\n",
        "        for i in range(n_layers-1):\n",
        "            _in = in_planes if i == 0 else _hidden\n",
        "            _hidden = int(_hidden // 1.5) if hidden is None else hidden\n",
        "            self.body.add_module('block%d'%(i+1),\n",
        "                                 torch.nn.Sequential(\n",
        "                                    #  nn.Dropout(0.2),\n",
        "                                     torch.nn.Linear(_in, _hidden),\n",
        "                                     torch.nn.BatchNorm1d(_hidden),\n",
        "                                     torch.nn.LeakyReLU(0.2)\n",
        "                                 ))\n",
        "        self.tail = torch.nn.Linear(_hidden, 1, bias=False)\n",
        "        self.apply(init_weight)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.body(x)\n",
        "        x = self.tail(x)\n",
        "        return x\n",
        "\n",
        "class Wave_Network(nn.Module):\n",
        "    def __init__(self, num_classes=12, model_path='', device='cuda'):\n",
        "        super().__init__()\n",
        "        self.device = device\n",
        "        self.backbone = Wav2Vec2Model.from_pretrained(model_path).to(device=device)\n",
        "\n",
        "        for param in self.backbone.parameters():\n",
        "            param.requires_grad = False\n",
        "        self.backbone.feature_extractor._freeze_parameters()\n",
        "\n",
        "        self.discriminator = Discriminator(768).to(device=device)\n",
        "        self.projection = Projection(768, 768, 2).to(device=device)\n",
        "        self.projector = nn.Sequential(\n",
        "            nn.Dropout(0.3),\n",
        "            nn.LazyLinear(256).to(device=device)\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(0.3),\n",
        "            # nn.Flatten(),\n",
        "            # nn.LazyLinear(256).to(device=device),\n",
        "            nn.LazyLinear(num_classes).to(device=device)\n",
        "        )\n",
        "\n",
        "    def get_train_params(self, is_classification=True):\n",
        "        if is_classification:\n",
        "            return [\n",
        "                {'params': self.projector.parameters()},\n",
        "                {'params': self.classifier.parameters()},\n",
        "            ]\n",
        "        else:\n",
        "            return [\n",
        "                {'params': self.projection.parameters()},\n",
        "                {'params': self.discriminator.parameters()},\n",
        "            ]\n",
        "\n",
        "    def forward(self, x, nomaly_label=None, std=0.05, is_train=True):\n",
        "        x = self.backbone(x).last_hidden_state\n",
        "        x_reshape = x.reshape(x.shape[0],-1)\n",
        "        x_hidden= F.adaptive_avg_pool1d(x_reshape, 768)\n",
        "        x_hidden_state = self.projector(x)\n",
        "        x_hidden_state = x_hidden_state.mean(dim=1)\n",
        "\n",
        "        if is_train:\n",
        "            normal_hidden_state = x_hidden_state[nomaly_label==1]\n",
        "            x_classification = self.classifier(normal_hidden_state)\n",
        "\n",
        "            x_projector = self.projection(x_hidden)\n",
        "            # add noise\n",
        "            # if is_train:\n",
        "            normal_x_projector = x_projector[nomaly_label==1]\n",
        "            noise = torch.normal(mean=0, std=std, size=normal_x_projector.shape).to(device=self.device)\n",
        "            x_noise = normal_x_projector + noise\n",
        "            x_noise = torch.concat((x_projector, x_noise))\n",
        "            # else:\n",
        "            #     x_noise = x_projector\n",
        "            x_anomaly = self.discriminator(x_noise)\n",
        "        else:\n",
        "            x_classification = self.classifier(x_hidden_state)\n",
        "            x_projector = self.projection(x_hidden)\n",
        "            x_anomaly = self.discriminator(x_projector)\n",
        "        return x_anomaly, x_classification\n",
        "\n",
        "    def save(self, file_path):\n",
        "        # Custom logic before saving\n",
        "        print(f\"Saving model to {file_path}\")\n",
        "\n",
        "        # For example, saving both the model's state dict and some metadata\n",
        "        torch.save({\n",
        "            'model_state_dict_backbone': self.backbone.state_dict(),\n",
        "            'model_state_dict_discriminator': self.discriminator.state_dict(),\n",
        "            'model_state_dict_projection': self.projection.state_dict(),\n",
        "            'model_state_dict_classifier': self.classifier.state_dict(),\n",
        "            'custom_metadata': {\n",
        "                'info': 'This is a custom saved model',\n",
        "                'epoch': 10,\n",
        "                'loss': 0.1234\n",
        "            }\n",
        "        }, file_path)\n",
        "\n",
        "        # Custom logic after saving\n",
        "        print(\"Model saved successfully!\")\n",
        "\n",
        "    def load(self, file_path):\n",
        "        # Custom logic before saving\n",
        "        print(f\"Loading model from {file_path}\")\n",
        "\n",
        "        # For example, saving both the model's state dict and some metadata\n",
        "        temp_model = torch.load(file_path)\n",
        "        self.backbone.load_state_dict(temp_model['model_state_dict_backbone'])\n",
        "        self.discriminator.load_state_dict(temp_model['model_state_dict_discriminator'])\n",
        "        self.projection.load_state_dict(temp_model['model_state_dict_projection'])\n",
        "        self.classifier.load_state_dict(temp_model['model_state_dict_classifier'])\n",
        "        # Custom logic after saving\n",
        "        print(\"Model loaded successfully!\")\n",
        "\n",
        "class Wave_Network_Classification(nn.Module):\n",
        "    def __init__(self, num_classes=12):\n",
        "        super().__init__()\n",
        "\n",
        "        self.projector = nn.Sequential(\n",
        "            # nn.Dropout(0.3),\n",
        "            # nn.Conv1d(49, 1, 3, padding='same'),\n",
        "            nn.LazyLinear(256)\n",
        "        )\n",
        "\n",
        "        self.squeeze_exhibition_in = nn.LazyLinear(16)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.squeeze_exhibition_out = nn.LazyLinear(49)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            # nn.Dropout(0.3),\n",
        "            nn.LazyLinear(num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, nomaly_label=None, is_train=True):\n",
        "        if nomaly_label is not None:\n",
        "            input_x = x[nomaly_label==1]\n",
        "        else:\n",
        "            input_x = x\n",
        "        x_hidden_state = self.projector(input_x) #[n, 49, 256]\n",
        "        # x_hidden_state = torch.squeeze(x_hidden_state)\n",
        "        # x_hidden_state_mean = x_hidden_state.mean(dim=1)\n",
        "        x_hidden_state_mean = x_hidden_state.mean(dim=-1) #[n, 49, 1]\n",
        "        x_hidden_state_mean = torch.unsqueeze(x_hidden_state_mean, 1)\n",
        "        # x_hidden_state_transpose = torch.transpose(x_hidden_state_mean, -1, -2) # [n, 1, 49]\n",
        "        x_squeeze_exhibition = self.squeeze_exhibition_in(x_hidden_state_mean)\n",
        "        x_squeeze_exhibition = self.relu(x_squeeze_exhibition)\n",
        "        x_squeeze_exhibition = self.squeeze_exhibition_out(x_squeeze_exhibition)\n",
        "        x_squeeze_exhibition = self.sigmoid(x_squeeze_exhibition)\n",
        "\n",
        "        x_hidden_state = torch.transpose(x_hidden_state, -1, -2)\n",
        "        x_hidden_state = torch.mul(x_hidden_state, x_squeeze_exhibition)\n",
        "        x_hidden_state = torch.transpose(x_hidden_state, -1, -2)\n",
        "\n",
        "        x_hidden_state = x_hidden_state.mean(dim=1)\n",
        "\n",
        "        if is_train:\n",
        "            normal_hidden_state = x_hidden_state\n",
        "            x_classification = self.classifier(normal_hidden_state)\n",
        "        else:\n",
        "            x_classification = self.classifier(x_hidden_state)\n",
        "        return x_classification\n",
        "\n",
        "class Wave_Network_Anomaly_Detection(nn.Module):\n",
        "    def __init__(self, std=0.05):\n",
        "        super().__init__()\n",
        "        self.discriminator = Discriminator(768)\n",
        "        self.projection = Projection(49, 768, 5)\n",
        "        self.std = std\n",
        "\n",
        "    def forward(self, x, nomaly_label=None, is_train=True):\n",
        "        # x_reshape = x.reshape(x.shape[0],-1)\n",
        "        # x_hidden= F.adaptive_avg_pool1d(x_reshape, 768)\n",
        "        # x_hidden = x.mean(dim=1)\n",
        "        x_hidden = x\n",
        "        if is_train:\n",
        "            x_projector = self.projection(x_hidden)\n",
        "            # add noise\n",
        "            # if is_train:\n",
        "            normal_x_projector = x_projector[nomaly_label==1]\n",
        "            noise = torch.normal(mean=0, std=self.std, size=normal_x_projector.shape).cuda()\n",
        "            x_noise = normal_x_projector + noise\n",
        "            x_noise = torch.concat((x_projector, x_noise))\n",
        "            # else:\n",
        "            #     x_noise = x_projector\n",
        "            x_anomaly = self.discriminator(x_noise)\n",
        "        else:\n",
        "            x_projector = self.projection(x_hidden)\n",
        "            x_anomaly = self.discriminator(x_projector)\n",
        "        return x_anomaly\n",
        "# _network =  Wav2Vec2Model.from_pretrained(pretrained_model_name_or_path='./model_1')\n",
        "# print(_network)\n",
        "# for name, param in _network.named_parameters():\n",
        "#     print(f\"layer: {name} | Shape: {param.shape}\")\n",
        "\n",
        "# model = AutoModelForAudioClassification.from_pretrained(\n",
        "#         pretrained_model_name_or_path='./model_1', num_labels=10, ignore_mismatched_sizes=True)\n",
        "# for name, param in model.named_parameters():\n",
        "#     print(f\"layer: {name} | Shape: {param.shape}\")"
      ],
      "metadata": {
        "id": "C9u3_YWaCXbm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "from transformers import Wav2Vec2Model, AutoFeatureExtractor, get_scheduler\n",
        "from datasets import Dataset, DatasetDict, Audio, concatenate_datasets\n",
        "from model.pure_model import Wave_Network_Classification, Wave_Network_Anomaly_Detection\n",
        "from torch.utils.data import DataLoader\n",
        "import evaluate\n",
        "accuracy = evaluate.load(\"accuracy\")\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from datasets import load_from_disk, Audio, VerificationMode, load_dataset\n",
        "import matplotlib.pyplot as plt\n",
        "from torchmetrics import F1Score, Precision, Recall, Accuracy\n",
        "from tqdm.auto import tqdm\n",
        "from data.audio_augmentation import random_augementation\n",
        "\n",
        "dict_label = {'yes':0,\n",
        "              'no':1,\n",
        "              'up':2,\n",
        "              'down':3,\n",
        "              'left':4,\n",
        "              'right':5,\n",
        "              'on':6,\n",
        "              'off':7,\n",
        "              'stop':8,\n",
        "              'go':9,\n",
        "              'unknown':10,\n",
        "              'silence':11}\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions = np.argmax(eval_pred.predictions, axis=1)\n",
        "    return accuracy.compute(predictions=predictions, references=eval_pred.label_ids)\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    audio_arrays = [x['array'] for x in examples[\"audio\"]]\n",
        "    inputs = feature_extractor(\n",
        "        audio_arrays, sampling_rate=feature_extractor.sampling_rate, padding=\"max_length\", max_length=16_000, truncation=True,\n",
        "    )\n",
        "    # inputs['input_values'] = model_backbone(torch.from_numpy(np.array(inputs['input_values'])).cuda()).last_hidden_state.cpu()\n",
        "    return inputs\n",
        "\n",
        "def agumentation_function(examples, i):\n",
        "    examples[\"audio\"]['array'] = random_augementation(examples[\"audio\"]['array'], i)\n",
        "\n",
        "    return examples\n",
        "\n",
        "def edit_label_2(seq):\n",
        "    if seq['label'] == 11:\n",
        "        seq['nomaly_label'] = 0\n",
        "    else:\n",
        "        seq['nomaly_label'] = 1\n",
        "    return seq\n",
        "\n",
        "def collate_fn(batch):\n",
        "    return_batch = {}\n",
        "    # Find the max length of sequences in the batch\n",
        "    max_len = max([len(x['input_values']) for x in batch])\n",
        "\n",
        "    # Pad sequences to the max length\n",
        "    for x in batch:\n",
        "        x['input_values'] = torch.cat([x['input_values'], torch.zeros(max_len - len(x['input_values']))])\n",
        "\n",
        "    return_batch['input_values'] = torch.stack([x['input_values'] for x in batch])\n",
        "    return_batch['label'] = torch.stack([x['label'] for x in batch])\n",
        "    return_batch['anomaly_label'] = torch.stack([x['anomaly_label'] for x in batch])\n",
        "\n",
        "    # Stack the padded sequences into a single tensor\n",
        "    return return_batch\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    model_path = './model_1'\n",
        "    weight_cls_state_dict = r'D:\\1.Project\\3.Machine_Learning\\Voice\\W2Vec\\models\\w2vec_model_cls_final - best.pth'\n",
        "    weight_anomaly_state_dict = r'D:\\1.Project\\3.Machine_Learning\\Voice\\W2Vec\\models\\w2vec_model_anomaly_final - best.pth'\n",
        "    epoch_num = 50\n",
        "    batch_size = 32\n",
        "    device = 'cuda'\n",
        "\n",
        "    label2id = {'yes': '0', 'no': '1', 'up': '2', 'down': '3', 'left': '4', 'right': '5', 'on': '6', 'off': '7', 'stop': '8', 'go': '9', 'unknown': '10', 'silence': '11'}\n",
        "    id2label = {'0':'yes', '1':'no', '2':'up', '3':'down', '4':'left', '5':'right', '6':'on', '7':'off', '8':'stop', '9':'go', '10':'unknown', '11':'silence'}\n",
        "\n",
        "    feature_extractor = AutoFeatureExtractor.from_pretrained(model_path)\n",
        "    model_backbone = Wav2Vec2Model.from_pretrained(model_path).to(device=device)\n",
        "    model_backbone.post_init()\n",
        "\n",
        "    for param in model_backbone.parameters():\n",
        "            param.requires_grad = False\n",
        "    model_backbone.feature_extractor._freeze_parameters()\n",
        "    # train_data = load_from_disk('./anomaly/data/dataset/train')\n",
        "    # valid_data = load_from_disk('./anomaly/data/dataset/validation')\n",
        "    # test_dataset = load_from_disk('./anomaly/data/dataset/test')\n",
        "    # dataset = load_dataset(\"superb\", \"ks\", trust_remote_code=True, verification_mode=VerificationMode.NO_CHECKS)\n",
        "    dataset = load_from_disk(r'D:\\1.Project\\3.Machine_Learning\\Voice\\anomaly\\data\\dataset\\superbs')\n",
        "    train_data = load_from_disk(r'D:\\1.Project\\3.Machine_Learning\\Voice\\anomaly\\data\\dataset\\superbs\\train_updated_augmentation_fake')\n",
        "    valid_data = dataset['validation']\n",
        "    test_dataset = dataset['test']\n",
        "\n",
        "    train_data = train_data.map(preprocess_function, remove_columns='audio', batched=True)\n",
        "    valid_data = valid_data.map(preprocess_function, remove_columns='audio', batched=True)\n",
        "    train_data = train_data.map(edit_label_2)\n",
        "    valid_data = valid_data.map(edit_label_2)\n",
        "\n",
        "    train_dataloader = DataLoader(train_data.with_format('torch'), batch_size, shuffle=True)\n",
        "    test_dataloader = DataLoader(valid_data.with_format('torch'), batch_size)\n",
        "\n",
        "    num_class = len(label2id) - 1\n",
        "    model_cls = Wave_Network_Classification(num_classes=num_class).to(device=device)\n",
        "    model_anomaly = Wave_Network_Anomaly_Detection().to(device=device)\n",
        "    model_cls.load_state_dict(torch.load(weight_cls_state_dict))\n",
        "    model_anomaly.load_state_dict(torch.load(weight_anomaly_state_dict))\n",
        "\n",
        "    criterion_1 = nn.CrossEntropyLoss()\n",
        "    criterion_2 = nn.BCEWithLogitsLoss()\n",
        "    optim_cls = torch.optim.AdamW(model_cls.parameters(), lr=0.001)\n",
        "    optim_anomaly = torch.optim.AdamW(model_anomaly.parameters(), lr=0.001)\n",
        "    acc_score_classification = Accuracy('multiclass', num_classes=num_class).to(device='cuda')\n",
        "    acc_score_anomaly = Accuracy('binary', num_classes=2).to(device='cuda')\n",
        "\n",
        "    num_training_steps = epoch_num * len(train_dataloader)\n",
        "    lr_scheduler_cls = get_scheduler(\n",
        "        name=\"linear\", optimizer=optim_cls, num_warmup_steps=0, num_training_steps=num_training_steps\n",
        "    )\n",
        "    lr_scheduler_anomaly = get_scheduler(\n",
        "        name=\"linear\", optimizer=optim_anomaly, num_warmup_steps=0, num_training_steps=num_training_steps\n",
        "    )\n",
        "    progress_bar = tqdm(range(num_training_steps), position=0, leave=True)\n",
        "\n",
        "    for epoch in range(epoch_num):\n",
        "        loss_item = 0.\n",
        "        valid_loss = 0.\n",
        "        running_loss = 0\n",
        "        save_loss = 999999\n",
        "        loss_item_1 = 0.\n",
        "        loss_item_2 = 0.\n",
        "        model_cls.train()\n",
        "        model_anomaly.train()\n",
        "        acc_score_classification.reset()\n",
        "        acc_score_anomaly.reset()\n",
        "        for i, data in enumerate(train_dataloader):\n",
        "            optim_cls.zero_grad()\n",
        "            optim_anomaly.zero_grad()\n",
        "            with torch.no_grad():\n",
        "                # data['input_values'] = model_backbone(data['input_values'].cuda()).extract_features\n",
        "                data['input_values'] = model_backbone(data['input_values'].cuda()).last_hidden_state\n",
        "            inputs, labels = data['input_values'].cuda(), data['nomaly_label'].cuda()\n",
        "            normal_inputs = data['input_values'][data['nomaly_label']==1].cuda()\n",
        "            anormal_inputs = data['input_values'][data['nomaly_label']==0].cuda()\n",
        "            normal_labels = data['label'][data['nomaly_label']==1].cuda()\n",
        "\n",
        "            if len(normal_inputs) == 0: continue\n",
        "\n",
        "            original_project_label = torch.unsqueeze(data['nomaly_label'], dim=-1)\n",
        "            false_project_label = torch.zeros(size=(normal_inputs.shape[0], 1))\n",
        "            projection_labels = torch.concat((original_project_label, false_project_label)).cuda()\n",
        "            o_classification = model_cls(inputs, labels)\n",
        "            o_nomaly = model_anomaly(inputs, labels)\n",
        "            loss_1 = criterion_1(o_classification, normal_labels)\n",
        "            loss_2 = criterion_2(o_nomaly, projection_labels)\n",
        "            loss = loss_1 + loss_2\n",
        "            f1_score_cls_metric = acc_score_classification(o_classification, normal_labels)\n",
        "            acc_score_anomaly_metric = acc_score_anomaly(o_nomaly, projection_labels)\n",
        "\n",
        "            loss_1.backward()\n",
        "            optim_cls.step()\n",
        "            lr_scheduler_cls.step()\n",
        "\n",
        "            loss_2.backward()\n",
        "            optim_anomaly.step()\n",
        "            lr_scheduler_anomaly.step()\n",
        "\n",
        "            loss_item_1 += loss_1.item()\n",
        "            loss_item_2 += loss_2.item()\n",
        "            progress_bar.update(1)\n",
        "            if i % 500 == 499:  # Print every 10 batches\n",
        "                tqdm.write(f'[Epoch {epoch + 1}, Batch {i + 1}] loss_cls: {loss_item_1/500:.3f} | loss_anomaly: {loss_item_2/500:.3f} | acc_cls_score: {acc_score_classification.compute():.3f} | acc_anomaly_score: {acc_score_anomaly.compute():.3f}')\n",
        "                loss_item_1 = 0.0\n",
        "                loss_item_2 = 0.0\n",
        "\n",
        "        model_cls.eval()\n",
        "        model_anomaly.eval()\n",
        "        acc_score_classification.reset()\n",
        "        acc_score_anomaly.reset()\n",
        "        with torch.no_grad():\n",
        "            for i, data in enumerate(test_dataloader):\n",
        "                data['input_values'] = model_backbone(data['input_values'].cuda()).last_hidden_state\n",
        "                # data['input_values'] = model_backbone(data['input_values'].cuda()).extract_features\n",
        "                inputs, labels = data['input_values'].cuda(), data['nomaly_label'].cuda()\n",
        "                normal_inputs = data['input_values'][data['nomaly_label']==1].cuda()\n",
        "                anormal_inputs = data['input_values'][data['nomaly_label']==0].cuda()\n",
        "                normal_labels = data['label'][data['nomaly_label']==1].cuda()\n",
        "                if len(normal_inputs) == 0: continue\n",
        "                # true_project_label = torch.ones(size=(normal_inputs.shape[0], 1))\n",
        "                original_project_label = torch.unsqueeze(data['nomaly_label'], dim=-1).cuda().float()\n",
        "                false_project_label = torch.zeros(size=(normal_inputs.shape[0], 1))\n",
        "                # projection_labels = torch.concat((original_project_label, false_project_label)).cuda()\n",
        "                o_classification = model_cls(normal_inputs, is_train=False)\n",
        "                o_nomaly = model_anomaly(inputs, labels, is_train=False)\n",
        "                loss_1 = criterion_1(o_classification, normal_labels)\n",
        "                loss_2 = criterion_2(o_nomaly, original_project_label)\n",
        "                loss = loss_1 + loss_2\n",
        "                valid_loss += loss.item()\n",
        "                f1_score_cls_metric = acc_score_classification(o_classification, normal_labels)\n",
        "                acc_score_anomaly_metric = acc_score_anomaly(o_nomaly, original_project_label)\n",
        "            valid_loss = valid_loss/len(test_dataloader)\n",
        "            if epoch == 0: valid_loss = save_loss\n",
        "            else:\n",
        "                if valid_loss < save_loss:\n",
        "                    torch.save(model_cls.state_dict(), f'./w2vec/models/w2vec_model_cls_best.pth')\n",
        "                    torch.save(model_anomaly.state_dict(), f'./w2vec/models/w2vec_model_anomaly_best.pth')\n",
        "                    save_loss = valid_loss\n",
        "            tqdm.write(f\"Epoch [{epoch+1}/{epoch_num}], Valid Loss: {valid_loss:.3f} | acc_cls_score: {acc_score_classification.compute():.3f} | acc_anomaly_score: {acc_score_anomaly.compute():.3f}\")\n",
        "\n",
        "    torch.save(model_cls.state_dict(), f'./w2vec/models/w2vec_model_cls_final.pth')\n",
        "    torch.save(model_anomaly.state_dict(), f'./w2vec/models/w2vec_model_anomaly_final.pth')\n"
      ],
      "metadata": {
        "id": "Q5JSHsikKS8g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "from transformers import AutoModelForAudioClassification, TrainingArguments, Trainer\n",
        "from transformers import AutoFeatureExtractor, Wav2Vec2Model\n",
        "from datasets import Dataset, DatasetDict, Audio\n",
        "from model.pure_model import Wave_Network\n",
        "from torch.utils.data import DataLoader\n",
        "import evaluate\n",
        "accuracy = evaluate.load(\"accuracy\")\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from datasets import load_from_disk, Audio\n",
        "import matplotlib.pyplot as plt\n",
        "from model.pure_model import Wave_Network_Classification, Wave_Network_Anomaly_Detection\n",
        "\n",
        "dict_label = {'yes':0,\n",
        "              'no':1,\n",
        "              'up':2,\n",
        "              'down':3,\n",
        "              'left':4,\n",
        "              'right':5,\n",
        "              'on':6,\n",
        "              'off':7,\n",
        "              'stop':8,\n",
        "              'go':9,\n",
        "              'silence':10,\n",
        "              'unknown':11}\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions = np.argmax(eval_pred.predictions, axis=1)\n",
        "    return accuracy.compute(predictions=predictions, references=eval_pred.label_ids)\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    audio_arrays = [x['array'] for x in examples[\"audio\"]]\n",
        "    inputs = feature_extractor(\n",
        "        audio_arrays, sampling_rate=feature_extractor.sampling_rate, padding=\"max_length\", max_length=16_000, truncation=True,\n",
        "    )\n",
        "    # inputs['input_values'] = model_backbone(torch.from_numpy(np.array(inputs['input_values'])).cuda()).last_hidden_state.cpu()\n",
        "    return inputs\n",
        "\n",
        "def collate_fn(batch):\n",
        "    return_batch = {}\n",
        "    # Find the max length of sequences in the batch\n",
        "    max_len = max([len(x['input_values']) for x in batch])\n",
        "\n",
        "    # Pad sequences to the max length\n",
        "    for x in batch:\n",
        "        x['input_values'] = torch.cat([x['input_values'], torch.zeros(max_len - len(x['input_values']))])\n",
        "\n",
        "    return_batch['input_values'] = torch.stack([x['input_values'] for x in batch])\n",
        "    return_batch['label'] = torch.stack([x['label'] for x in batch])\n",
        "    return_batch['nomaly_label'] = torch.stack([x['nomaly_label'] for x in batch])\n",
        "    # return_batch['re_label'] = torch.stack([x['re_label'] for x in batch])\n",
        "    return return_batch\n",
        "\n",
        "def edit_label_2(seq):\n",
        "    if seq['label'] == 11:\n",
        "        seq['nomaly_label'] = 0\n",
        "    else:\n",
        "        seq['nomaly_label'] = 1\n",
        "    return seq\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    model_path = './model_1'\n",
        "    device = 'cuda'\n",
        "    weight_state_dict_cls = './w2vec/models/w2vec_model_cls_best.pth'\n",
        "    weight_state_dict_anomaly = './w2vec/models/w2vec_model_anomaly_best.pth'\n",
        "    feature_extractor = AutoFeatureExtractor.from_pretrained(model_path)\n",
        "    model_backbone = Wav2Vec2Model.from_pretrained(model_path).to(device=device)\n",
        "\n",
        "    model_cls = Wave_Network_Classification(num_classes=11).to(device=device)\n",
        "    model_anomaly = Wave_Network_Anomaly_Detection().to(device=device)\n",
        "    epoch_num = 30\n",
        "    batch_size = 1\n",
        "\n",
        "    label2id = {'yes': '0', 'no': '1', 'up': '2', 'down': '3', 'left': '4', 'right': '5', 'on': '6', 'off': '7', 'stop': '8', 'go': '9', 'silence': '10', 'unknown': '11'}\n",
        "    id2label = {'0':'yes', '1':'no', '2':'up', '3':'down', '4':'left', '5':'right', '6':'on', '7':'off', '8':'stop', '9':'go', '10':'silence', '11':'unknown'}\n",
        "\n",
        "    dataset = load_from_disk(r'D:\\1.Project\\3.Machine_Learning\\Voice\\anomaly\\data\\dataset\\superbs')\n",
        "    test_dataset = dataset['test']\n",
        "\n",
        "    test_dataset = test_dataset.map(preprocess_function, remove_columns='audio', batched=True)\n",
        "    test_dataset = test_dataset.map(edit_label_2)\n",
        "    print(test_dataset)\n",
        "    test_dataset_loader = DataLoader(test_dataset.with_format('torch'), batch_size, shuffle=True)\n",
        "    num_class = len(label2id) - 1\n",
        "    model_cls.load_state_dict(torch.load(weight_state_dict_cls))\n",
        "    model_anomaly.load_state_dict(torch.load(weight_state_dict_anomaly))\n",
        "\n",
        "    loss_item = 0.\n",
        "    model_cls.eval()\n",
        "    model_anomaly.eval()\n",
        "    acc = 0\n",
        "    with torch.no_grad():\n",
        "        for i, data in enumerate(test_dataset_loader):\n",
        "            data['input_values'] = model_backbone(data['input_values'].cuda()).last_hidden_state\n",
        "            inputs = data['input_values'].cuda()\n",
        "            o_classification = model_cls(inputs, is_train=False)\n",
        "            o_nomaly = model_anomaly(inputs, is_train=False)\n",
        "            anomaly_arg = torch.sigmoid(o_nomaly)\n",
        "            cls_arg = torch.argmax(o_classification, dim=-1)\n",
        "            if (anomaly_arg.cpu().item() > 0.5 and data['nomaly_label'].cpu().item() == 1):\n",
        "                if data['label'].cpu().item() != 11 and cls_arg.cpu().item() == data['label'].cpu().item():\n",
        "                    acc += 1\n",
        "                else:\n",
        "                    print(anomaly_arg, data['nomaly_label'], cls_arg, data['label'])\n",
        "            elif anomaly_arg.cpu().item() <= 0.5 and data['nomaly_label'].cpu().item() == 0:\n",
        "                acc += 1\n",
        "            else:\n",
        "                print(anomaly_arg, data['nomaly_label'], cls_arg, data['label'])\n",
        "        print(f'acc: {acc/len(test_dataset)}')\n"
      ],
      "metadata": {
        "id": "fvOTsuYIKU2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_from_disk, concatenate_datasets, Dataset, Audio, ClassLabel\n",
        "import numpy as np\n",
        "import scipy.io.wavfile as wav\n",
        "import random\n",
        "import soundfile as sf\n",
        "from typing import Dict, Optional, Union\n",
        "import scipy, acoustics, pandas\n",
        "import matplotlib.pyplot as plt\n",
        "from audio_augmentation import random_augementation\n",
        "import librosa\n",
        "\n",
        "LABEL_IDS = {'yes': '0', 'no': '1', 'up': '2', 'down': '3', 'left': '4', 'right': '5', 'on': '6', 'off': '7', 'stop': '8', 'go': '9', 'unknown': '10', 'silence': '11'}\n",
        "\n",
        "NOISE_AUDIO_PATH_ARRAYS = [\n",
        "    r'D:\\1.Project\\3.Machine_Learning\\Voice\\anomaly\\data\\SpeechCommands\\speech_commands_v0.01\\_background_noise_\\doing_the_dishes.wav',\n",
        "    r'D:\\1.Project\\3.Machine_Learning\\Voice\\anomaly\\data\\SpeechCommands\\speech_commands_v0.01\\_background_noise_\\dude_miaowing.wav',\n",
        "    r'D:\\1.Project\\3.Machine_Learning\\Voice\\anomaly\\data\\SpeechCommands\\speech_commands_v0.01\\_background_noise_\\exercise_bike.wav',\n",
        "    r'D:\\1.Project\\3.Machine_Learning\\Voice\\anomaly\\data\\SpeechCommands\\speech_commands_v0.01\\_background_noise_\\running_tap.wav',\n",
        "]\n",
        "class Audio_Implement(Audio):\n",
        "    def decode_example(self, value: dict, token_per_repo_id: Optional[Dict[str, Union[str, bool, None]]] = None) -> dict:\n",
        "        return {\"path\": value[\"path\"], \"array\": value['array'], \"sampling_rate\": value['sampling_rate']}\n",
        "\n",
        "def get_noise_data_sources():\n",
        "    data_bank = []\n",
        "    for path in NOISE_AUDIO_PATH_ARRAYS:\n",
        "        audio_data, sample_rate = sf.read(path)\n",
        "        data_bank.append((audio_data, sample_rate))\n",
        "    return data_bank\n",
        "\n",
        "def random_crop_wav(data_bank, idx, crop_duration=1):\n",
        "    # Load the wav file\n",
        "    audio_data, sample_rate = data_bank[idx]\n",
        "\n",
        "    # Calculate total length of audio in seconds\n",
        "    total_duration = len(audio_data) / sample_rate\n",
        "\n",
        "    # Ensure that the crop duration is valid\n",
        "    if crop_duration > total_duration:\n",
        "        raise ValueError(\"Crop duration exceeds the audio length.\")\n",
        "\n",
        "    # Convert crop duration to samples\n",
        "    crop_samples = int(crop_duration * sample_rate)\n",
        "\n",
        "    # Determine a random start point\n",
        "    max_start = len(audio_data) - crop_samples\n",
        "    start_sample = random.randint(0, max_start)\n",
        "\n",
        "    # Crop the audio\n",
        "    cropped_audio = audio_data[start_sample:start_sample + crop_samples]\n",
        "\n",
        "    # Convert to numpy array (if not already)\n",
        "    cropped_array = np.array(cropped_audio)\n",
        "\n",
        "    return cropped_array, sample_rate\n",
        "\n",
        "def create_random_data(data_count = 1800):\n",
        "    out_data = []\n",
        "    data_bank = get_noise_data_sources()\n",
        "    for i in range(data_count):\n",
        "        # random method:\n",
        "        rand_method = random.randint(0, 1)\n",
        "        # crop\n",
        "        if rand_method == 0:\n",
        "            arr, sample_rate = random_crop_wav(data_bank=data_bank, idx=random.randint(0, 3))\n",
        "        else:\n",
        "            rand_noise_method = random.randint(0, 1)\n",
        "            # white noise\n",
        "            if rand_noise_method == 1:\n",
        "                scipy.io.wavfile.write('white_noise.wav', 16000, np.array(((acoustics.generator.noise(16000*1, color='white'))/3) * 32767).astype(np.int16))\n",
        "                arr, sample_rate = sf.read('white_noise.wav')\n",
        "            # pink noise\n",
        "            else:\n",
        "                scipy.io.wavfile.write('pink_noise.wav', 16000, np.array(((acoustics.generator.noise(16000*1, color='pink'))/3) * 32767).astype(np.int16))\n",
        "                arr, sample_rate = sf.read('pink_noise.wav')\n",
        "        out_data.append((arr, sample_rate))\n",
        "        print(f'{i} create file..', arr)\n",
        "    return out_data\n",
        "\n",
        "def add_data_to_dataset(input_dataset, input_data, label=10):\n",
        "    input_dict = input_dataset.to_dict()\n",
        "    pd = input_dataset.to_pandas()\n",
        "    da = Dataset.from_pandas(pd)\n",
        "    for i, data in enumerate(input_data):\n",
        "        input_dict['file'].append(f'added_audio_file_{i}')\n",
        "        input_dict['audio'].append({\n",
        "                    'path': f'added_audio_file_{i}',\n",
        "                    'array': data[0],\n",
        "                    'sampling_rate': data[1]\n",
        "                })\n",
        "        input_dict['label'].append(label)\n",
        "\n",
        "    output_dataset = Dataset.from_dict(input_dict)\n",
        "    return output_dataset\n",
        "\n",
        "def agumentation_function(examples, i):\n",
        "    if examples['label'] != 11:\n",
        "        examples[\"audio\"]['array'] = random_augementation(examples[\"audio\"]['array'], i)\n",
        "    return examples\n",
        "\n",
        "import os\n",
        "def _prepare_file_list(root_dir):\n",
        "    file_paths = []\n",
        "    labels = []\n",
        "\n",
        "    for idx, (root, _, files) in enumerate(os.walk(root_dir)):\n",
        "        random.shuffle(files)\n",
        "        for file in files:\n",
        "            if file.endswith(\".wav\"):\n",
        "                file_paths.append(os.path.join(root, file))\n",
        "                file_idx = int(file.split('_')[1][:3])\n",
        "                labels.append(file_idx)\n",
        "    return file_paths, labels\n",
        "\n",
        "def create_new_dataset(input_data, label=10, is_create_dataset_from_folder=False, root_path=None):\n",
        "    input_dict = {\n",
        "        'file': [],\n",
        "        'audio': [],\n",
        "        'label': []\n",
        "    }\n",
        "    for i, data in enumerate(input_data):\n",
        "        input_dict['file'].append(f'added_audio_file_{i}')\n",
        "        input_dict['audio'].append({\n",
        "                    'path': f'added_audio_file_{i}',\n",
        "                    'array': data[0],\n",
        "                    'sampling_rate': data[1]\n",
        "                })\n",
        "        input_dict['label'].append(label)\n",
        "        print(i, data[0], data[1])\n",
        "\n",
        "    if is_create_dataset_from_folder and root_path:\n",
        "        file_paths, labels = _prepare_file_list(root_path)\n",
        "        for i, data in enumerate(list(zip(file_paths, labels))):\n",
        "            audio_arr, sr = sf.read(data[0])\n",
        "            audio_arr = librosa.resample(audio_arr, orig_sr=sr, target_sr=16_000)\n",
        "            input_dict['file'].append(f'added_fake_audio_file_{i}')\n",
        "            input_dict['audio'].append({\n",
        "                    'path': f'added_fake_audio_file_{i}',\n",
        "                    'array': audio_arr,\n",
        "                    'sampling_rate': 16_000\n",
        "                })\n",
        "            input_dict['label'].append(data[1])\n",
        "            print(i, data[0], data[1])\n",
        "    output_dataset = Dataset.from_dict(input_dict)\n",
        "    return output_dataset\n",
        "\n",
        "\n",
        "path = r'D:\\1.Project\\3.Machine_Learning\\Voice\\anomaly\\data\\dataset\\superbs\\fake_data'\n",
        "# _prepare_file_list(path)\n",
        "\n",
        "dataset = load_from_disk(r'D:\\1.Project\\3.Machine_Learning\\Voice\\anomaly\\data\\dataset\\superbs\\train_updated_augmentation')\n",
        "# train_dataset = dataset['train']\n",
        "\n",
        "data = create_random_data(data_count=700)\n",
        "new_dataset = create_new_dataset(data, is_create_dataset_from_folder=True, root_path=path)\n",
        "new_dataset = new_dataset.cast_column('audio', Audio(sampling_rate=16_000))\n",
        "new_dataset = new_dataset.cast_column('label', ClassLabel(names=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', '_silence_', '_unknown_']))\n",
        "print(new_dataset)\n",
        "# train_dataset = concatenate_datasets([train_dataset, new_dataset], info=train_dataset.info)\n",
        "\n",
        "dataset = concatenate_datasets([dataset, new_dataset])\n",
        "for i in range(6):\n",
        "    print(f'Round: {i}')\n",
        "    augementation_train_data = new_dataset.filter(lambda x: x['label'] != 11).map(agumentation_function, fn_kwargs={'i': i})\n",
        "    dataset = concatenate_datasets([dataset, augementation_train_data])\n",
        "print(dataset)\n",
        "\n",
        "\n",
        "df = dataset.to_pandas()\n",
        "# Gi s ct label trong dataset c tn l 'label'\n",
        "label_counts = df['label'].value_counts()\n",
        "# Hin th kt qu\n",
        "print(label_counts)\n",
        "dataset.save_to_disk(r'D:\\1.Project\\3.Machine_Learning\\Voice\\anomaly\\data\\dataset\\superbs\\train_updated_augmentation_fake')\n",
        "# print('done')"
      ],
      "metadata": {
        "id": "eu9lU4j-KY1m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "import torchaudio.transforms as T\n",
        "from scipy.signal import butter, lfilter\n",
        "import random\n",
        "\n",
        "def time_stretch(audio, rate=1.2):\n",
        "    return librosa.effects.time_stretch(audio, rate=rate)\n",
        "\n",
        "def pitch_shift(audio, sr, n_steps=2):\n",
        "    return librosa.effects.pitch_shift(audio, sr=sr, n_steps=n_steps)\n",
        "\n",
        "def add_noise(audio, noise_factor=0.005):\n",
        "    noise = np.random.randn(len(audio))\n",
        "    augmented_audio = audio + noise_factor * noise\n",
        "    return augmented_audio\n",
        "\n",
        "def shift_time(audio, shift_max=0.2, sr=16000):\n",
        "    shift = np.random.randint(sr * shift_max) # shift in seconds\n",
        "    return np.roll(audio, shift)\n",
        "\n",
        "def change_volume(audio, factor=1.5):\n",
        "    return audio * factor\n",
        "\n",
        "def spec_augment(mel_spectrogram):\n",
        "    time_mask = T.TimeMasking(time_mask_param=30)\n",
        "    freq_mask = T.FrequencyMasking(freq_mask_param=30)\n",
        "    augmented_spec = time_mask(mel_spectrogram)\n",
        "    augmented_spec = freq_mask(augmented_spec)\n",
        "    return augmented_spec\n",
        "\n",
        "def reverb(audio, sr=16000):\n",
        "    # Example using librosa's reverb effect\n",
        "    room_size = 0.5\n",
        "    return librosa.effects.preemphasis(audio, coef=room_size)\n",
        "\n",
        "def butter_lowpass(cutoff, fs, order=5):\n",
        "    nyq = 0.5 * fs\n",
        "    normal_cutoff = cutoff / nyq\n",
        "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
        "    return b, a\n",
        "\n",
        "def lowpass_filter(audio, cutoff, sr):\n",
        "    b, a = butter_lowpass(cutoff, sr, order=6)\n",
        "    y = lfilter(b, a, audio)\n",
        "    return y\n",
        "\n",
        "def random_augementation(audio, rand_method):\n",
        "    if rand_method is None:\n",
        "        rand_method = random.randint(0, 5)\n",
        "    if rand_method == 0:\n",
        "        return time_stretch(audio=audio)\n",
        "    elif rand_method == 1:\n",
        "        return pitch_shift(audio=audio, sr=16_000)\n",
        "    elif rand_method ==2:\n",
        "        noise_fc = random.uniform(0.001, 0.005)\n",
        "        return add_noise(audio=audio, noise_factor=noise_fc)\n",
        "    elif rand_method ==3:\n",
        "        return change_volume(audio=audio)\n",
        "    elif rand_method ==4:\n",
        "        return reverb(audio=audio, sr=16_000)\n",
        "    elif rand_method ==5:\n",
        "        return shift_time(audio=audio, sr=16_000)\n",
        "\n",
        "# audioo = np.zeros((16000,))\n",
        "# x = time_stretch(audio=audioo, rate=1.2)\n",
        "# print(x)"
      ],
      "metadata": {
        "id": "3pMbHbuoKZit"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Making the Most of your Colab Subscription",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}